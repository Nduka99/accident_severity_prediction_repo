# Hybrid MLOps Implementation Plan (Educational Guide)

## Goal Description
We are building a professional-grade "Hybrid" ML application. This splits our app into two distinct parts:
1.  **Backend (API)**: A "headless" server that takes data and returns predictions. It runs inside a Docker container.
2.  **Frontend (UI)**: An interactive website that talks to the backend.

**Why this approach?**
This mimics how big tech companies build software. It separates concerns: the data scientists improve the model (Backend), and engineers improve the user experience (Frontend) without breaking each other's work.

## User Review Required
> [!IMPORTANT]
> **GitHub Repo**: I still need your GitHub Repository URL to connect your local code to the cloud.
> **Docker Desktop**: You must have Docker Desktop installed and running on your Windows machine to build the container locally.

## Detailed Step-by-Step Process

### Step 1: Git Hygiene & Project Structure
**Concept**: Before writing code, we prepare our workspace. We tell Git what *not* to track (like our huge dataset) so we don't crash the repo.
*   **Action**: Create `.gitignore`.
*   **Git Integration**: We will `git init`, `git add .gitignore`, and `git commit` as our very first action.

### Step 2: The Backend (FastAPI)
**Concept**: We are wrapping your [lgbm_tuned_model.pkl](file:///c:/Users/nwagb/Desktop/MACHINE_LEARNING_ASSESSEMENT/us_accident_prediction_model/lgbm_tuned_model.pkl) in a web server. Think of this like replacing a Python script execution with a website URL.
*   **Action**: Create `backend/main.py`.
    *   **Input**: Defines the "shape" of data we expect (Temperature, Humidity, etc.) using `Pydantic`. This prevents bad data from crashing the model.
    *   **Logic**: Loads the model once on startup (efficient) and predicts on request.
    *   **Output**: Returns a JSON like `{"risk_score": 0.85}`.
*   **Git Integration**: `git add backend/` -> `git commit -m "feat: add inference api"`.

### Step 3: Containerization (Docker)
**Concept**: "It works on my machine" is the enemy. Docker freezes your OS, Python version, and libraries into a "Image". If it runs in Docker on your PC, it will run *anywhere*.
*   **Action**: Create `Dockerfile`.
    *   `FROM python:3.9-slim`: Start with a lightweight Linux.
    *   `COPY . /app`: Move our code inside.
    *   `RUN pip install`: Install libraries inside the container.
    *   `CMD uvicorn`: Command to start the server.
*   **Validation**: We will build this image and run it. You will see the API working on `localhost`.

### Step 4: The Frontend (Streamlit)
**Concept**: Users don't speak JSON. Streamlit provides the buttons and sliders. It will act as a *client* to our API.
*   **Action**: Create `frontend/app.py`.
    *   It renders a form.
    *   When "Predict" is clicked, it sends a message (HTTP POST) to our running Backend Docker container.
    *   It displays the result beautifully.

### Step 5: CI/CD (GitHub Actions)
**Concept**: MLOps is about automation. We don't want to manually check if our code works every time we save.
*   **Action**: Create `.github/workflows/ci.yml`.
    *   **Trigger**: Whenever you `git push`.
    *   **Job**: GitHub's servers will virtually checkout your code, install Python, and run a check to ensure no syntax errors exist.
    *   **Why**: This is the first "Gate" of a pipeline.

## Proposed Changes

### Project Structure
New folders `backend/` and `frontend/` to keep things clean.

#### [NEW] [.gitignore](file:///c:/Users/nwagb/Desktop/MACHINE_LEARNING_ASSESSEMENT/us_accident_prediction_model/.gitignore)
- Essential to block `*.csv` and `__pycache__`.

#### [NEW] [backend/main.py](file:///c:/Users/nwagb/Desktop/MACHINE_LEARNING_ASSESSEMENT/us_accident_prediction_model/backend/main.py)
- The FastAPI application.

#### [NEW] [Dockerfile](file:///c:/Users/nwagb/Desktop/MACHINE_LEARNING_ASSESSEMENT/us_accident_prediction_model/Dockerfile)
- The blueprint for our backend container.

#### [NEW] [frontend/app.py](file:///c:/Users/nwagb/Desktop/MACHINE_LEARNING_ASSESSEMENT/us_accident_prediction_model/frontend/app.py)
- The user interface.

#### [NEW] [requirements.txt](file:///c:/Users/nwagb/Desktop/MACHINE_LEARNING_ASSESSEMENT/us_accident_prediction_model/requirements.txt)
- Combined dependencies for now (or split if we want to be strict).

## Verification Plan
1.  **Local API Test**: Run backend, use `curl` to get a prediction.
2.  **Docker Test**: Build image, run container, get a prediction.
3.  **End-to-End**: Run Frontend -> calls Docker Backend -> Model predicts -> UI updates.
